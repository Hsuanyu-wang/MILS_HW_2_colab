{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0xLLdV9wyZxovMoNbboyg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hsuanyu-wang/MILS_HW_2_colab/blob/main/MILS_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download dataset"
      ],
      "metadata": {
        "id": "IyOJhkomP5Yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/MILS_HW_2/scripts/download_coco_det.py"
      ],
      "metadata": {
        "id": "iDqTxgadOqmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/MILS_HW_2/scripts/download_imagenette_cls.py"
      ],
      "metadata": {
        "id": "vpGn82s-Oz10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/MILS_HW_2/scripts/download_voc_seg.py"
      ],
      "metadata": {
        "id": "jSsiCSgnO0Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### main process"
      ],
      "metadata": {
        "id": "fOop7tlYP5Bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Verifying downloads...\")\n",
        "import os\n",
        "data_paths = {\n",
        "    'seg': './data/VOCdevkit/VOC2012',\n",
        "    'det': './data/coco_subset',\n",
        "    'cls': './data/imagenette2-160'\n",
        "}\n",
        "\n",
        "for task, path in data_paths.items():\n",
        "    if os.path.exists(path):\n",
        "        print(f\"{task} dataset found at {path}\")\n",
        "    else:\n",
        "        print(f\"WARNING: {task} dataset not found at {path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Myhr5fwcP4yY",
        "outputId": "23e43671-a975-422f-ea46-9743703a6cf6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verifying downloads...\n",
            "seg dataset found at ./data/VOCdevkit/VOC2012\n",
            "det dataset found at ./data/coco_subset\n",
            "cls dataset found at ./data/imagenette2-160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "%cd /content/MILS_HW_2\n",
        "\n",
        "from src.models.unified_model import UnifiedModel\n",
        "from src.datasets.data_loaders import create_dataloaders\n",
        "from src.training.loss_functions import MultiTaskLoss, UncertaintyWeightedLoss\n",
        "from configs.config import Config  # 使用Config類\n",
        "\n",
        "# 初始化配置\n",
        "config = Config()  # 創建Config實例，不是模組\n",
        "\n",
        "# 初始化損失函數\n",
        "criterion = MultiTaskLoss()\n",
        "print(\"Loss functions initialized\")\n",
        "\n",
        "# 初始化模型\n",
        "model = UnifiedModel()\n",
        "print(f\"Total parameters: {sum(p.numel() for p in model.parameters())/1e6:.1f}M\")\n",
        "\n",
        "# 創建數據載入器 (根據你的下載檔案)\n",
        "print(\"Loading datasets...\")\n",
        "dataloaders = create_dataloaders(\n",
        "    batch_size=config.batch_size,\n",
        "    num_workers=config.num_workers\n",
        ")\n",
        "print(\"dataloaders\", dataloaders)\n",
        "\n",
        "# 準備datasets字典給trainer使用 (只用train set)\n",
        "datasets = {\n",
        "    'seg': dataloaders['seg']['train'],\n",
        "    'seg_val': dataloaders['seg']['val'],\n",
        "    'det': dataloaders['det']['train'],\n",
        "    'det_val': dataloaders['det']['val'],\n",
        "    'cls': dataloaders['cls']['train'],\n",
        "    'cls_val': dataloaders['cls']['val']\n",
        "}\n",
        "print(\"datasets:\\n\", datasets)\n",
        "print(\"Datasets loaded successfully!\")\n",
        "print(f\"Detection batches: {len(datasets['det'])}\")\n",
        "print(f\"Segmentation batches: {len(datasets['seg'])}\")\n",
        "print(f\"Classification batches: {len(datasets['cls'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "GO6WX--cP4wJ",
        "outputId": "de2b53fb-725c-4edb-865b-028f3ab1a131"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MILS_HW_2\n",
            "Loss functions initialized\n",
            "Total parameters: 3.2M\n",
            "Loading datasets...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Dataset not found or corrupted. You can use download=True to download it",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-951118673>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# 創建數據載入器 (根據你的下載檔案)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading datasets...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m dataloaders = create_dataloaders(\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/MILS_HW_2/src/datasets/data_loaders.py\u001b[0m in \u001b[0;36mcreate_dataloaders\u001b[0;34m(batch_size, num_workers)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_dataloaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;34m\"\"\"創建DataLoaders\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_datasets_from_downloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mdataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/MILS_HW_2/src/datasets/data_loaders.py\u001b[0m in \u001b[0;36mcreate_datasets_from_downloads\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# 1. VOC Segmentation (根據你的download_voc_seg.py)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     voc_train = VOCSegmentation(\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2012'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/voc.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, year, image_set, download, transform, target_transform, transforms)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset not found or corrupted. You can use download=True to download it\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0msplits_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ImageSets\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SPLITS_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Dataset not found or corrupted. You can use download=True to download it"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.models.unified_model import UnifiedModel\n",
        "from src.datasets.data_loaders import create_dataloaders\n",
        "from src.training.loss_functions import MultiTaskLoss, UncertaintyWeightedLoss\n",
        "from configs.config import Config  # 使用Config類\n",
        "\n",
        "# 初始化配置\n",
        "config = Config()  # 創建Config實例，不是模組\n",
        "\n",
        "# 初始化損失函數\n",
        "criterion = MultiTaskLoss()\n",
        "print(\"Loss functions initialized\")\n",
        "\n",
        "# 初始化模型\n",
        "model = UnifiedModel()\n",
        "print(f\"Total parameters: {sum(p.numel() for p in model.parameters())/1e6:.1f}M\")\n",
        "\n",
        "# 創建數據載入器 (根據你的下載檔案)\n",
        "print(\"Loading datasets...\")\n",
        "dataloaders = create_dataloaders(\n",
        "    batch_size=config.batch_size,\n",
        "    num_workers=config.num_workers\n",
        ")\n",
        "print(\"dataloaders\", dataloaders)\n",
        "\n",
        "# 準備datasets字典給trainer使用 (只用train set)\n",
        "datasets = {\n",
        "    'seg': dataloaders['seg']['train'],\n",
        "    'seg_val': dataloaders['seg']['val'],\n",
        "    'det': dataloaders['det']['train'],\n",
        "    'det_val': dataloaders['det']['val'],\n",
        "    'cls': dataloaders['cls']['train'],\n",
        "    'cls_val': dataloaders['cls']['val']\n",
        "}\n",
        "print(\"datasets:\\n\", datasets)\n",
        "print(\"Datasets loaded successfully!\")\n",
        "print(f\"Detection batches: {len(datasets['det'])}\")\n",
        "print(f\"Segmentation batches: {len(datasets['seg'])}\")\n",
        "print(f\"Classification batches: {len(datasets['cls'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "KAU61zi7P4t5",
        "outputId": "515c9485-3e03-4437-f775-293b971cc6b0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'src'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1045093260>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munified_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUnifiedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiTaskLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUncertaintyWeightedLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfig\u001b[0m  \u001b[0;31m# 使用Config類\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.models.unified_model import UnifiedModel\n",
        "from src.datasets.data_loaders import create_dataloaders\n",
        "from src.training.loss_functions import MultiTaskLoss, UncertaintyWeightedLoss\n",
        "from configs.config import Config  # 使用Config類\n",
        "\n",
        "# 初始化配置\n",
        "config = Config()  # 創建Config實例，不是模組\n",
        "\n",
        "# 初始化損失函數\n",
        "criterion = MultiTaskLoss()\n",
        "print(\"Loss functions initialized\")\n",
        "\n",
        "# 初始化模型\n",
        "model = UnifiedModel()\n",
        "print(f\"Total parameters: {sum(p.numel() for p in model.parameters())/1e6:.1f}M\")\n",
        "\n",
        "# 創建數據載入器 (根據你的下載檔案)\n",
        "print(\"Loading datasets...\")\n",
        "dataloaders = create_dataloaders(\n",
        "    batch_size=config.batch_size,\n",
        "    num_workers=config.num_workers\n",
        ")\n",
        "print(\"dataloaders\", dataloaders)\n",
        "\n",
        "# 準備datasets字典給trainer使用 (只用train set)\n",
        "datasets = {\n",
        "    'seg': dataloaders['seg']['train'],\n",
        "    'seg_val': dataloaders['seg']['val'],\n",
        "    'det': dataloaders['det']['train'],\n",
        "    'det_val': dataloaders['det']['val'],\n",
        "    'cls': dataloaders['cls']['train'],\n",
        "    'cls_val': dataloaders['cls']['val']\n",
        "}\n",
        "print(\"datasets:\\n\", datasets)\n",
        "print(\"Datasets loaded successfully!\")\n",
        "print(f\"Detection batches: {len(datasets['det'])}\")\n",
        "print(f\"Segmentation batches: {len(datasets['seg'])}\")\n",
        "print(f\"Classification batches: {len(datasets['cls'])}\")"
      ],
      "metadata": {
        "id": "lhEMYOrkP4rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hrG9IKy2QuBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f963513c"
      },
      "source": [
        "# Task\n",
        "Resolve the `RuntimeError: Dataset not found or corrupted.` when loading the VOC dataset in the notebook. Inspect the data loading code in \"/content/MILS_HW_2/src/datasets/data_loaders.py\" and the dataset structure at \"./data/VOCdevkit/VOC2012\", modify the code as needed, and confirm the issue is resolved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "615f011c"
      },
      "source": [
        "## Inspect `create dataloaders` and `create datasets from downloads`\n",
        "\n",
        "### Subtask:\n",
        "Examine the code in the `create_dataloaders` and `create_datasets_from_downloads` functions within `/content/MILS_HW_2/src/datasets/data_loaders.py` to understand how the VOC dataset is being loaded and if the paths are correctly specified.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b286ccb"
      },
      "source": [
        "**Reasoning**:\n",
        "To understand how the VOC dataset is loaded and identify potential path issues, I need to examine the relevant functions in the `data_loaders.py` file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc67e3c0",
        "outputId": "53e857e0-34a4-4e6d-fe86-567a2ac1fb04"
      },
      "source": [
        "# Inspect the data_loaders.py file\n",
        "with open('/content/MILS_HW_2/src/datasets/data_loaders.py', 'r') as f:\n",
        "    data_loaders_code = f.read()\n",
        "\n",
        "print(data_loaders_code)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# src/datasets/data_loaders.py\n",
            "import torch\n",
            "from torch.utils.data import DataLoader, Dataset, Subset\n",
            "from torchvision import transforms, datasets\n",
            "from torchvision.datasets import VOCSegmentation\n",
            "from pycocotools.coco import COCO\n",
            "from PIL import Image\n",
            "import os\n",
            "import numpy as np\n",
            "\n",
            "def get_transforms():\n",
            "    \"\"\"根據作業要求的transforms\"\"\"\n",
            "    transform = transforms.Compose([\n",
            "        transforms.Resize((224, 224)),\n",
            "        transforms.ToTensor(),\n",
            "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
            "                           std=[0.229, 0.224, 0.225])\n",
            "    ])\n",
            "    \n",
            "    # Fixed mask transform for VOC segmentation\n",
            "    def mask_transform(mask):\n",
            "        # Resize first as PIL Image\n",
            "        mask = mask.resize((224, 224), Image.NEAREST)\n",
            "        # Convert to tensor and handle VOC format\n",
            "        mask = torch.from_numpy(np.array(mask)).long()\n",
            "        # Keep 255 as ignore index (don't convert to 0 here)\n",
            "        return mask\n",
            "    \n",
            "    return transform, mask_transform\n",
            "\n",
            "class COCODetectionDataset(Dataset):\n",
            "    \"\"\"基於你的download_coco_det.py的COCO數據集\"\"\"\n",
            "    def __init__(self, root_dir='./data/coco_subset', split='train', transform=None):\n",
            "        self.root_dir = root_dir\n",
            "        self.split = split\n",
            "        self.transform = transform\n",
            "        \n",
            "        # 載入COCO annotations (根據你的下載檔案)\n",
            "        ann_file = os.path.join(root_dir, 'annotations', f'instances_{split}2017.json')\n",
            "        self.coco = COCO(ann_file)\n",
            "        \n",
            "        # 你下載的10個類別\n",
            "        self.categories = [\"person\", \"car\", \"bicycle\", \"motorcycle\", \"airplane\",\n",
            "                          \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\"]\n",
            "        self.cat_ids = self.coco.getCatIds(catNms=self.categories)\n",
            "        \n",
            "        # 獲取圖片ID\n",
            "        img_ids = []\n",
            "        for cat_id in self.cat_ids:\n",
            "            img_ids.extend(self.coco.getImgIds(catIds=[cat_id]))\n",
            "        self.img_ids = list(set(img_ids))\n",
            "        \n",
            "        # 根據你的下載數量限制\n",
            "        if split == 'train':\n",
            "            self.img_ids = self.img_ids[:240]\n",
            "        else:  # val\n",
            "            self.img_ids = self.img_ids[:60]\n",
            "    \n",
            "    def __len__(self):\n",
            "        return len(self.img_ids)\n",
            "    \n",
            "    def __getitem__(self, idx):\n",
            "        img_id = self.img_ids[idx]\n",
            "        img_info = self.coco.loadImgs([img_id])[0]\n",
            "        img_path = os.path.join(self.root_dir, f'{self.split}2017', img_info['file_name'])\n",
            "        image = Image.open(img_path).convert('RGB')\n",
            "        if self.transform:\n",
            "            image = self.transform(image)\n",
            "        # 取得annotation（這裡僅簡單返回所有該圖的標註，實際可根據需要處理）\n",
            "        ann_ids = self.coco.getAnnIds(imgIds=[img_id], catIds=self.cat_ids, iscrowd=None)\n",
            "        anns = self.coco.loadAnns(ann_ids)\n",
            "        return {\n",
            "            'image': image,\n",
            "            'targets': anns,  # 這裡直接返回COCO格式annotation\n",
            "            'img_id': img_id\n",
            "        }\n",
            "\n",
            "class ClassificationDataset(Dataset):\n",
            "    \"\"\"包裝ImageFolder，返回dict格式\"\"\"\n",
            "    def __init__(self, image_folder):\n",
            "        self.image_folder = image_folder\n",
            "    def __len__(self):\n",
            "        return len(self.image_folder)\n",
            "    def __getitem__(self, idx):\n",
            "        image, label = self.image_folder[idx]\n",
            "        return {'image': image, 'label': label}\n",
            "\n",
            "def create_datasets_from_downloads():\n",
            "    \"\"\"根據你的下載檔案創建數據集\"\"\"\n",
            "    \n",
            "    transform, mask_transform = get_transforms()\n",
            "    \n",
            "    # 1. VOC Segmentation (根據你的download_voc_seg.py)\n",
            "    voc_train = VOCSegmentation(\n",
            "        root='./data',\n",
            "        year='2012',\n",
            "        image_set='train',\n",
            "        download=False,\n",
            "        transform=transform,\n",
            "        target_transform=mask_transform\n",
            "    )\n",
            "    voc_train_subset = Subset(voc_train, list(range(240)))\n",
            "    \n",
            "    voc_val = VOCSegmentation(\n",
            "        root='./data',\n",
            "        year='2012', \n",
            "        image_set='val',\n",
            "        download=False,\n",
            "        transform=transform,\n",
            "        target_transform=mask_transform\n",
            "    )\n",
            "    voc_val_subset = Subset(voc_val, list(range(60)))\n",
            "    \n",
            "    # 2. Imagenette Classification (根據你的download_imagenette_cls.py)\n",
            "    imagenette_train = datasets.ImageFolder(\n",
            "        root='./data/imagenette2-160/train',\n",
            "        transform=transform\n",
            "    )\n",
            "    imagenette_train_subset = Subset(imagenette_train, list(range(240)))\n",
            "    imagenette_train_dataset = ClassificationDataset(imagenette_train_subset)\n",
            "    \n",
            "    imagenette_val = datasets.ImageFolder(\n",
            "        root='./data/imagenette2-160/val', \n",
            "        transform=transform\n",
            "    )\n",
            "    imagenette_val_subset = Subset(imagenette_val, list(range(60)))\n",
            "    imagenette_val_dataset = ClassificationDataset(imagenette_val_subset)\n",
            "    \n",
            "    # 3. COCO Detection (根據你的download_coco_det.py)\n",
            "    coco_train = COCODetectionDataset(\n",
            "        root_dir='./data/coco_subset',\n",
            "        split='train',\n",
            "        transform=transform\n",
            "    )\n",
            "    \n",
            "    coco_val = COCODetectionDataset(\n",
            "        root_dir='./data/coco_subset', \n",
            "        split='val',\n",
            "        transform=transform\n",
            "    )\n",
            "    \n",
            "    return {\n",
            "        'seg': {'train': voc_train_subset, 'val': voc_val_subset},\n",
            "        'cls': {'train': imagenette_train_dataset, 'val': imagenette_val_dataset}, \n",
            "        'det': {'train': coco_train, 'val': coco_val}\n",
            "    }\n",
            "\n",
            "def create_dataloaders(batch_size=16, num_workers=2):\n",
            "    \"\"\"創建DataLoaders\"\"\"\n",
            "    datasets = create_datasets_from_downloads()\n",
            "    \n",
            "    dataloaders = {}\n",
            "    for task in ['seg', 'cls', 'det']:\n",
            "        dataloaders[task] = {\n",
            "            'train': DataLoader(\n",
            "                datasets[task]['train'],\n",
            "                batch_size=batch_size,\n",
            "                shuffle=True,\n",
            "                num_workers=num_workers\n",
            "            ),\n",
            "            'val': DataLoader(\n",
            "                datasets[task]['val'], \n",
            "                batch_size=batch_size,\n",
            "                shuffle=False,\n",
            "                num_workers=num_workers\n",
            "            )\n",
            "        }\n",
            "    \n",
            "    return dataloaders\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f468d34c"
      },
      "source": [
        "## Verify dataset structure\n",
        "\n",
        "### Subtask:\n",
        "Verify the actual file structure of the downloaded VOC dataset at `./data/VOCdevkit/VOC2012` to ensure it matches the structure expected by `torchvision.datasets.voc`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6398ae24"
      },
      "source": [
        "**Reasoning**:\n",
        "List the contents of the VOC dataset directory to verify its structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "fd7a4deb",
        "outputId": "3c6b3cb0-6dc9-4442-aca9-7439bad92ce6"
      },
      "source": [
        "import os\n",
        "\n",
        "voc_path = './data/VOCdevkit/VOC2012'\n",
        "print(f\"Listing contents of {voc_path}:\")\n",
        "for item in os.listdir(voc_path):\n",
        "    print(item)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing contents of ./data/VOCdevkit/VOC2012:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './data/VOCdevkit/VOC2012'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-3894508368>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvoc_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./data/VOCdevkit/VOC2012'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Listing contents of {voc_path}:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/VOCdevkit/VOC2012'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13f14ae7"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to list the directory contents failed because the directory was not found. This indicates the VOC dataset was not downloaded or extracted to the expected location during the initial download steps. The download script for VOC segmentation was `!python /content/MILS_HW_2/scripts/download_voc_seg.py`. Let's inspect this script to see where it intends to place the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjnzPshaRo40",
        "outputId": "2d402089-6cfa-47a1-e1ea-64057a61fd37"
      },
      "source": [
        "# Inspect the download_voc_seg.py script\n",
        "with open('/content/MILS_HW_2/scripts/download_voc_seg.py', 'r') as f:\n",
        "    download_script_code = f.read()\n",
        "\n",
        "print(download_script_code)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import torch\n",
            "from torch.utils.data import Subset\n",
            "from torchvision import datasets, transforms\n",
            "from torchvision.datasets import VOCSegmentation\n",
            "\n",
            "voc2012_detection_train = VOCSegmentation(\n",
            "    root='./data',           # 資料集存放目錄\n",
            "    year='2012',            # 年份設定為2012\n",
            "    image_set='train',      # 可選擇 'train', 'trainval', 'val'\n",
            "    download=True,          # 自動下載\n",
            "    transform=None,         # 可選的圖像變換\n",
            "    target_transform=None   # 可選的標籤變換\n",
            ")\n",
            "\n",
            "# 選擇前500筆VOC資料\n",
            "voc_subset = Subset(voc2012_detection_train, list(range(240)))\n",
            "\n",
            "voc2012_detection_val = VOCSegmentation(\n",
            "    root='./data',           # 資料集存放目錄\n",
            "    year='2012',            # 年份設定為2012\n",
            "    image_set='val',      # 可選擇 'train', 'trainval', 'val'\n",
            "    download=True,          # 自動下載\n",
            "    transform=None,         # 可選的圖像變換\n",
            "    target_transform=None   # 可選的標籤變換\n",
            ")\n",
            "\n",
            "voc_subset = Subset(voc2012_detection_val, list(range(60)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "580b7efd"
      },
      "source": [
        "**Reasoning**:\n",
        "The inspection of `download_voc_seg.py` shows that it attempts to download the VOC Segmentation dataset using `torchvision.datasets.VOCSegmentation` with `download=True` and `root='./data'`. However, the previous attempt to list the directory contents at `./data/VOCdevkit/VOC2012` resulted in a `FileNotFoundError`. This suggests that despite `download=True`, the dataset might not have been successfully downloaded or placed in the expected structure by `torchvision`. The `create_dataloaders` function also uses `VOCSegmentation` with `root='./data'`, which is likely causing the `RuntimeError` in the previous execution. Since the dataset was not found, I need to rerun the download script to ensure the data is present before attempting to load it again. I will then try listing the directory contents again to verify the structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96b79ca4",
        "outputId": "be13e8ab-079e-4000-deb4-a00dbca7ded7"
      },
      "source": [
        "# Rerun the download script for VOC segmentation\n",
        "!python /content/MILS_HW_2/scripts/download_voc_seg.py\n",
        "\n",
        "# Verify the directory structure again after rerunning the download script\n",
        "import os\n",
        "\n",
        "voc_path = './data/VOCdevkit/VOC2012'\n",
        "print(f\"Listing contents of {voc_path}:\")\n",
        "try:\n",
        "    for item in os.listdir(voc_path):\n",
        "        print(item)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Directory not found after download attempt: {voc_path}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 59% 1.19G/2.00G [05:14<06:47, 2.00MB/s]"
          ]
        }
      ]
    }
  ]
}